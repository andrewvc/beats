################### Heartbeat Configuration Example #########################

# This file is an example configuration file highlighting only some common options.
# The heartbeat.reference.yml file in the same directory contains all the supported options
# with detailed comments. You can use it for reference.
#
# You can find the full configuration reference here:
# https://www.elastic.co/guide/en/beats/heartbeat/index.html

############################# Heartbeat ######################################

# Define a directory to load monitor definitions from. Definitions take the form
# of individual yaml files.
heartbeat.config.monitors:
  # Directory + glob pattern to search for configuration files
  path: ${path.config}/monitors.d/*.yml
  # If enabled, heartbeat will periodically check the config.monitors path for changes
  reload.enabled: false
  # How often to check for changes
  reload.period: 5s

# Configure monitors inline
heartbeat.monitors:
- type: http

  # List or urls to query
  urls: ["http://localhost:9200"]

  # Configure task schedule
  schedule: '@every 10s'

  # Total test connection and data exchange timeout
  #timeout: 16s

#==================== Elasticsearch template setting ==========================

setup.template.settings:
  index.number_of_shards: 1
  index.codec: best_compression
  #_source.enabled: false

setup.data_frame:
  transforms:
    - pipeline:
        name: foo
        definition:
      mappings:
        dynamic: false
        properties:
          monitor_id:
            type: keyword
          state:
            properties:
              "@timestamp":
                type: date
              observer:
                properties:
                  geo:
                    properties:
                      name:
                        type: keyword
                      location:
                        type: geo_point
              agent:
                properties:
                  id:
                    type: keyword
              up:
                type: integer
              down:
                type: integer
              monitor:
                properties:
                  status:
                    type: keyword
                  name:
                    type: keyword
                  id:
                    type: keyword
                  ip:
                    type: ip
              url:
                properties:
                  domain:
                    type: keyword
                    ignore_above: 1024
                  fragment:
                    type: keyword
                    ignore_above: 1024
                  full:
                    type: keyword
                    ignore_above: 1024
                  original:
                    type: keyword
                    ignore_above: 1024
                  password:
                    type: keyword
                    ignore_above: 1024
                  path:
                    type: keyword
                    ignore_above: 1024
                  port:
                    type: long
                  query:
                    type: keyword
                    ignore_above: 1024
                  scheme:
                    type: keyword
                    ignore_above: 1024
                  username:
                    type: keyword
                    ignore_above: 1024
              checks:
                type: nested
                properties:
                  "@timestamp":
                    type: date
                  monitor:
                    type: object
                    properties:
                      ip:
                        type: ip
                      status:
                        type: keyword
                  agent:
                    properties:
                      id:
                        type: keyword
                  observer:
                    properties:
                      geo:
                        type: object
                        properties:
                          name:
                            type: keyword
                          location:
                            type: geo_point
      pivot:
        group_by:
          monitor_id: {"terms": {"field": "monitor.id"}}
        aggregations:
          state:
            scripted_metric:
              init_script: |
                // Globals are values that should be identical across all docs
                // We can cheat a bit by always overwriting these and make the
                // assumption that there is no variation in these across checks
                state.globals = new HashMap();
                // Here we store stuff broken out by agent.id and monitor.id
                // This should correspond to a unique check.
                state.checksByAgentIdIP = new HashMap();
              map_script: |
                Map curCheck = new HashMap();
                String agentId = doc["agent.id"][0];
                String ip = doc["monitor.ip"][0];
                String agentIdIP = agentId + "-" + ip.toString();
                def ts = doc["@timestamp"][0].toInstant().toEpochMilli();

                def lastCheck = state.checksByAgentIdIP[agentId];
                Long lastTs = lastCheck != null ? lastCheck["@timestamp"] : null;
                if (lastTs != null && lastTs > ts) {
                  return;
                }

                curCheck.put("@timestamp", ts);

                Map agent = new HashMap();
                agent.id = agentId;
                curCheck.put("agent", agent);

                if (state.globals.url == null) {
                  Map url = new HashMap();
                  Collection fields = ["full", "original", "scheme", "username", "password", "domain", "port", "path", "query", "fragment"];
                  url.full = doc["url.full"];
                  for (field in fields) {
                    String docPath = "url." + field;
                    def val = doc[docPath];
                    if (!val.isEmpty()) {
                      url[field] = val[0];
                    }
                  }
                  state.globals.url = url;
                }

                Map monitor = new HashMap();
                monitor.status = doc["monitor.status"][0];
                monitor.ip = ip;
                def monitorName = doc["monitor.name"][0];
                if (monitorName != "") {
                  monitor.name = monitorName;
                }
                curCheck.monitor = monitor;

                if (curCheck.observer == null) {
                  curCheck.observer = new HashMap();
                }
                if (curCheck.observer.geo == null) {
                  curCheck.observer.geo = new HashMap();
                }
                if (!doc["observer.geo.name"].isEmpty()) {
                  curCheck.observer.geo.name = doc["observer.geo.name"][0];
                }
                if (!doc["observer.geo.location"].isEmpty()) {
                  curCheck.observer.geo.location = doc["observer.geo.location"][0];
                }

                state.checksByAgentIdIP[agentIdIP] = curCheck;
              combine_script: |
                return state;
              reduce_script: |
                // The final document
                Map result = new HashMap();

                Map checks = new HashMap();
                long maxTs = 0;
                Collection ips = new HashSet();
                Collection geoNames = new HashSet();
                for (state in states) {
                  result.putAll(state.globals);
                  for (entry in state.checksByAgentIdIP.entrySet()) {
                    def agentIdIP = entry.getKey();
                    def check = entry.getValue();
                    def lastBestCheck = checks.get(agentIdIP);
                    def checkTs = check.get("@timestamp");

                    if (maxTs < checkTs) { maxTs = checkTs}

                    if (lastBestCheck == null || lastBestCheck.get("@timestamp") < checkTs) {
                      checks[agentIdIP] = check
                    }


                    ips.add(check.monitor.ip);
                    if (check.observer != null && check.observer.geo != null && check.observer.geo.name != null) {
                      geoNames.add(check.observer.geo.name);
                    }
                  }
                }

                // We just use the values so we can store these as nested docs
                result.checks = checks.values();
                result.put("@timestamp", maxTs);


                Map summary = new HashMap();
                summary.up = checks.entrySet().stream().filter(c -> c.getValue().status == "up").count();
                summary.down = checks.size() - summary.up;
                result.summary = summary;

                Map monitor = new HashMap();
                monitor.ip = ips;
                monitor.status = summary.down > 0 ? (summary.up > 0 ? "mixed": "down") : "up";
                result.monitor = monitor;

                Map observer = new HashMap();
                Map geo = new HashMap();
                geo.name = geoNames;
                result.observer = observer;
                result.geo = geo;

                return result;

#================================ General =====================================

# The name of the shipper that publishes the network data. It can be used to group
# all the transactions sent by a single shipper in the web interface.
#name:

# The tags of the shipper are included in their own field with each
# transaction published.
#tags: ["service-X", "web-tier"]

# Optional fields that you can specify to add additional information to the
# output.
#fields:
#  env: staging


#============================== Dashboards =====================================
# These settings control loading the sample dashboards to the Kibana index. Loading
# the dashboards is disabled by default and can be enabled either by setting the
# options here or by using the `setup` command.
#setup.dashboards.enabled: false

# The URL from where to download the dashboards archive. By default this URL
# has a value which is computed based on the Beat name and version. For released
# versions, this URL points to the dashboard archive on the artifacts.elastic.co
# website.
#setup.dashboards.url:

#============================== Kibana =====================================

# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.
# This requires a Kibana endpoint configuration.
setup.kibana:

  # Kibana Host
  # Scheme and port can be left out and will be set to the default (http and 5601)
  # In case you specify and additional path, the scheme is required: http://localhost:5601/path
  # IPv6 addresses should always be defined as: https://[2001:db8::1]:5601
  #host: "localhost:5601"

  # Kibana Space ID
  # ID of the Kibana Space into which the dashboards should be loaded. By default,
  # the Default Space will be used.
  #space.id:

#============================= Elastic Cloud ==================================

# These settings simplify using heartbeat with the Elastic Cloud (https://cloud.elastic.co/).

# The cloud.id setting overwrites the `output.elasticsearch.hosts` and
# `setup.kibana.host` options.
# You can find the `cloud.id` in the Elastic Cloud web UI.
#cloud.id:

# The cloud.auth setting overwrites the `output.elasticsearch.username` and
# `output.elasticsearch.password` settings. The format is `<user>:<pass>`.
#cloud.auth:

#================================ Outputs =====================================

# Configure what output to use when sending the data collected by the beat.

#-------------------------- Elasticsearch output ------------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["localhost:9200"]

  # Optional protocol and basic auth credentials.
  #protocol: "https"
  #username: "elastic"
  #password: "changeme"

#----------------------------- Logstash output --------------------------------
#output.logstash:
  # The Logstash hosts
  #hosts: ["localhost:5044"]

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"

#================================ Processors =====================================
processors:
  - add_observer_metadata: 
  # Optional, but recommended geo settings for the location heartbeat is running in 
  #geo: 
    # Token describing this location
    #name: us-east-1a

    # Lat, Lon "
    #location: "37.926868, -78.024902"


#================================ Logging =====================================

# Sets log level. The default log level is info.
# Available log levels are: error, warning, info, debug
#logging.level: debug

# At debug level, you can selectively enable logging only for some components.
# To enable all selectors use ["*"]. Examples of other selectors are "beat",
# "publish", "service".
#logging.selectors: ["*"]

#============================== Xpack Monitoring ===============================
# heartbeat can export internal metrics to a central Elasticsearch monitoring
# cluster.  This requires xpack monitoring to be enabled in Elasticsearch.  The
# reporting is disabled by default.

# Set to true to enable the monitoring reporter.
#monitoring.enabled: false

# Uncomment to send the metrics to Elasticsearch. Most settings from the
# Elasticsearch output are accepted here as well.
# Note that the settings should point to your Elasticsearch *monitoring* cluster.
# Any setting that is not set is automatically inherited from the Elasticsearch
# output configuration, so if you have the Elasticsearch output configured such
# that it is pointing to your Elasticsearch monitoring cluster, you can simply
# uncomment the following line.
#monitoring.elasticsearch:

#================================= Migration ==================================

# This allows to enable 6.7 migration aliases
#migration.6_to_7.enabled: true
